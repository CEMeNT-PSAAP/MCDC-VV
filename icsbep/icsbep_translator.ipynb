{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as et\n",
    "from lxml import etree\n",
    "import numpy as np\n",
    "import h5py, os, sys\n",
    "\n",
    "try:\n",
    "    import openmc\n",
    "except ImportError:\n",
    "    None\n",
    "\n",
    "AVAGADRO = 6.02214076e23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Functions Relating to Materials_XML_Parser\n",
    "def Atomic_Mass(Nuc):  # Temp Solution, simplifies to the Atomic Mass Number\n",
    "    # Pulls Data from the NIST Nuclude Data file if it exists\n",
    "    if os.path.exists(\"nist-nuclide-data.txt\"):\n",
    "        Symbol = \"\"\n",
    "        Mass_Num = \"\"\n",
    "        for _ in Nuc:\n",
    "            try:\n",
    "                int(_)\n",
    "                Mass_Num += _\n",
    "            except:\n",
    "                Symbol += _\n",
    "        Mass_Num = int(Mass_Num)\n",
    "        NAT_AB = False\n",
    "        if Symbol == \"H\":\n",
    "            if Mass_Num == 2:\n",
    "                Symbol = \"D\"\n",
    "            elif Mass_Num == 3:\n",
    "                Symbol = \"T\"\n",
    "        if any([_ == Symbol for _ in [\"C\", \"Zn\", \"Pt\", \"Os\", \"Tl\"]]) and Mass_Num == 0:\n",
    "            NAT_AB = True\n",
    "        with open(\"nist-nuclide-data.txt\", \"r\") as Data:\n",
    "            Data_Lines = Data.readlines()[:]\n",
    "            for n, line in enumerate(Data_Lines):\n",
    "                if line[16:-1] == Symbol:\n",
    "                    if int(Data_Lines[n + 1][14:-1]) == Mass_Num:\n",
    "                        AM = float(Data_Lines[n + 2][23:-1].split(\"(\")[0])\n",
    "                        break\n",
    "                    elif NAT_AB:\n",
    "                        AM = float(Data_Lines[n + 4][25:-1].split(\"(\")[0])\n",
    "                        break\n",
    "            Data_Lines.clear()\n",
    "    # Runs OpenMC function if NIST data does not exist and OpenMC module is installed\n",
    "    elif \"openmc\" in sys.modules:\n",
    "        AM = openmc.atomic_mass(Nuc)\n",
    "    # Approximates atomic mass to atomic mass number (int) if either other method fails\n",
    "    else:\n",
    "        AM = \"\"\n",
    "        for _ in Nuc:\n",
    "            try:\n",
    "                AM += str(int(_))\n",
    "            except:\n",
    "                None\n",
    "        AM = int(AM)\n",
    "        print(\n",
    "            f\"WARNING: Using integer approximation for {Nuc}.\\nEnsure nist-nuclide-data.txt or OpenMC are available.\"\n",
    "        )\n",
    "    return AM\n",
    "\n",
    "\n",
    "def Average_Molar_Mass(Material=[], Percent=[], Percent_Type=[]):\n",
    "    # Fuction pulled from OpenMC, calculates avg molar mass based on nuclide composition\n",
    "    mass = 0\n",
    "    moles = 0\n",
    "    assert len(Material) == len(Percent_Type) == len(Percent)\n",
    "    for i in range(len(Material)):\n",
    "        if Percent_Type[i] == \"ao\":\n",
    "            mass += Percent[i] * Atomic_Mass(Material[i])\n",
    "            moles += Percent[i]\n",
    "        elif Percent_Type[i] == \"wo\":\n",
    "            mass += Percent[i]\n",
    "            moles += Percent[i] / Atomic_Mass(Material[i])\n",
    "    return mass / moles\n",
    "\n",
    "\n",
    "def Reconstruct_Scatter_Matrix(Data=dict()):\n",
    "    # Method only works if Scatter Data is saved properly by OpenMC cross sections file\n",
    "    Flat_Scatter = np.array(\n",
    "        Data[\"scatter_data\"][\"scatter_matrix\"]\n",
    "    )  # Pulls Mx1 scatter data\n",
    "    g_min = (\n",
    "        np.array(Data[\"scatter_data\"][\"g_min\"]) - 1\n",
    "    )  # Determines min group number of rows\n",
    "    g_max = (\n",
    "        np.array(Data[\"scatter_data\"][\"g_max\"]) - 1\n",
    "    )  # Determines max group number of rows\n",
    "    Num_Groups = len(g_min)\n",
    "    Scatter_Matrix = np.zeros([Num_Groups, Num_Groups])\n",
    "    for i in range(Num_Groups):\n",
    "        N = g_max[i] - g_min[i] + 1  # Defines N values to pull from Mx1 scatter data\n",
    "        Scatter_Matrix[i, g_min[i] : g_max[i] + 1] = Flat_Scatter[\n",
    "            :N\n",
    "        ]  # Fills GxG matrix from min to max of row i\n",
    "        Flat_Scatter = np.delete(Flat_Scatter, range(N))  # Removes used data\n",
    "    Scatter_Matrix = np.transpose(\n",
    "        Scatter_Matrix\n",
    "    )  # Proper formatting for Scatter Matrix\n",
    "    return Scatter_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Functions Relating to Geometry_XML_Parser\n",
    "def Region_Fill(py_file=None, Cell=dict()):\n",
    "    if py_file == None:\n",
    "        py_file = open(\"_.py\", \"t+a\")\n",
    "    Regions = Cell.get(\"region\")\n",
    "    if Regions != None:\n",
    "        Region_IDs = np.array([val for val in Regions.split()])\n",
    "        # py_file.write(\"region=\") # Temporarily removed in case of redundancy\n",
    "    else:\n",
    "        return  # Exits function if cell has no regions\n",
    "\n",
    "    Skip = True\n",
    "    for i in range(len(Region_IDs)):\n",
    "        Region_ID = Region_IDs[i]\n",
    "        # Runs through CSG operators, skips '&' for '|', continues if left blank\n",
    "        if not Skip and Region_ID[0] != \"|\":\n",
    "            py_file.write(\" & \")\n",
    "        if Region_ID[0] == \"~\":\n",
    "            py_file.write(\"~\")\n",
    "            Region_ID = Region_ID[1:]\n",
    "        elif Region_ID[0] == \"|\":\n",
    "            py_file.write(\" | \")\n",
    "            Region_ID = Region_ID[1:]\n",
    "        Skip = False\n",
    "        if Region_ID == \"\":\n",
    "            Skip = True\n",
    "            continue\n",
    "        # Looks for parathesis goruping and ensures only ID int remains\n",
    "        while type(Region_ID) == str or type(Region_ID) == np.str_:\n",
    "            if Region_ID[0] == \"(\":\n",
    "                py_file.write(\"(\")\n",
    "                Region_ID = Region_ID[1:]\n",
    "            if Region_ID[-1] == \")\":\n",
    "                close_join += 1\n",
    "                Region_ID = Region_ID[:-1]\n",
    "            else:\n",
    "                close_join = 0\n",
    "            try:\n",
    "                Region_ID = int(Region_ID)\n",
    "            except:\n",
    "                None\n",
    "        # Applys + or - half-spaces, then writes surface into region\n",
    "        if Region_ID > 0:\n",
    "            r_sign = \"+\"\n",
    "        elif Region_ID < 0:\n",
    "            r_sign = \"-\"\n",
    "        py_file.write(f\"{r_sign}s{int(abs(Region_ID))}\")\n",
    "        py_file.write(close_join * \")\")  # Closes grouped and subgrouped regions\n",
    "    py_file.write(\", \")\n",
    "    if py_file.name == \"_.py\":\n",
    "        py_file.close()\n",
    "\n",
    "\n",
    "def Write_Universes(\n",
    "    Geom_Root,\n",
    "    py_file,\n",
    "    Lat_ID=None,\n",
    "    Complex=False,\n",
    "    Exclude_List=None,\n",
    "    Defined_Cells=None,\n",
    "):\n",
    "    global created_universes\n",
    "\n",
    "    Univ_Data = np.array([[0, 0]])\n",
    "    Written_Universes = []\n",
    "    for Cell in Geom_Root.findall(\"cell\"):\n",
    "        if (\n",
    "            Cell.get(\"material\") != None and Lat_ID == None and not Complex\n",
    "        ):  # Pulls material universes\n",
    "            Univ_ID = int(Cell.get(\"universe\"))\n",
    "            Cell_ID = int(Cell.get(\"id\"))\n",
    "            Univ_Data = np.append(Univ_Data, np.array([[Univ_ID, Cell_ID]]), axis=0)\n",
    "        elif (\n",
    "            Cell.get(\"fill\") != None and Lat_ID == None and Complex\n",
    "        ):  # Pulls complex universes that are not excluded\n",
    "            if int(Cell.get(\"fill\")) in Exclude_List:\n",
    "                continue\n",
    "            Univ_ID = int(Cell.get(\"universe\"))\n",
    "            Cell_ID = int(Cell.get(\"id\"))\n",
    "            Univ_Data = np.append(Univ_Data, np.array([[Univ_ID, Cell_ID]]), axis=0)\n",
    "        elif Cell.get(\"fill\") == str(Lat_ID):  # Pulls lattice univere with specified ID\n",
    "            Univ_ID = int(Cell.get(\"universe\"))\n",
    "            Cell_ID = int(Cell.get(\"id\"))\n",
    "            Univ_Data = np.append(Univ_Data, np.array([[Univ_ID, Cell_ID]]), axis=0)\n",
    "    if Univ_Data.shape != (1, 2):\n",
    "        # Constructs Univsere dictionary grouping cell IDs to Universe IDs\n",
    "        Univ_Data = np.delete(Univ_Data, 0, 0).T\n",
    "        Univ_Dict = {\n",
    "            n: rep[n]\n",
    "            for rep in [{}]\n",
    "            for i, n in enumerate(Univ_Data[0, :])\n",
    "            if rep.setdefault(n, []).append(i) or len(rep[n]) == 1\n",
    "        }\n",
    "        for key in Univ_Dict:\n",
    "            if Complex:\n",
    "                if not all(\n",
    "                    [\n",
    "                        (_ in Defined_Cells)\n",
    "                        for _ in [Univ_Data[1, i] for i in Univ_Dict[key]]\n",
    "                    ]\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "            if (\n",
    "                key not in created_universes\n",
    "            ):  # If u# is not already defined, it creates u# with initial cells\n",
    "                py_file.write(f\"u{key} = mcdc.universe([\")\n",
    "                created_universes.append(key)\n",
    "            else:  # If u# was already defined, uses u#.add_cells with new cells\n",
    "                py_file.write(f\"u{key}.add_cells([\")\n",
    "            for j, i in enumerate(Univ_Dict[key]):\n",
    "                py_file.write(f\"c{Univ_Data[1,i]}\")\n",
    "                if i != Univ_Dict[key][-1]:\n",
    "                    py_file.write(\", \")\n",
    "                if j % 20 == 19:\n",
    "                    py_file.write(\n",
    "                        \"\\n\\t\\t\"\n",
    "                    )  # Moves to next line if there are more than 20 cells/line, compacts formatting\n",
    "            if (key == 0) and (key not in created_universes):\n",
    "                py_file.write(\n",
    "                    \"], root=True])\\n\"\n",
    "                )  # If OpenMC uses universe 0 as root, sets u0 as the root universe\n",
    "            else:\n",
    "                py_file.write(\"])\\n\")\n",
    "            Written_Universes.append(int(key))\n",
    "\n",
    "    return Written_Universes\n",
    "\n",
    "\n",
    "def Write_Rect_Lattice(Lattice, py_file, Lat_ID=None):\n",
    "    # Creates lattice configuration for 1D, 2D, or 3D rectangular lattices, Hexagonal lattices not implemented yet.\n",
    "    # Identifies individual lattices based on Lat_ID\n",
    "    py_file.write(f\"\\n# Rectangular Lattice {Lat_ID}\\n\")\n",
    "    if Lattice.get(\"name\") != None:\n",
    "        py_file.write(f\"# Name: {Lattice.get('name')}\\n\")\n",
    "    py_file.write(f\"Lattice{Lat_ID} = mcdc.lattice(\")\n",
    "    dims = np.array([int(val) for val in Lattice.find(\"dimension\").text.split()])\n",
    "    pitch = np.array([float(val) for val in Lattice.find(\"pitch\").text.split()])\n",
    "    Lower_Left = np.array(\n",
    "        [float(val) for val in Lattice.find(\"lower_left\").text.split()]\n",
    "    )\n",
    "    xyz_str = [\"x\", \"y\", \"z\"]\n",
    "    for i in range(len(pitch)):\n",
    "        py_file.write(\n",
    "            \"{}=[{}, {}, {}], \".format(xyz_str[i], Lower_Left[i], pitch[i], dims[i])\n",
    "        )\n",
    "    # Pulls lattice str from xml and reformats into desired shape based on dimensions\n",
    "    Lattice_xml = np.array(Lattice.find(\"universes\").text.split(\"\\n\"))\n",
    "    Lattice_xml = np.delete(Lattice_xml, np.where(Lattice_xml == \"\"))\n",
    "    Lattice_xml = np.array([ind.split() for ind in Lattice_xml]).flat\n",
    "    Lattice_xml = np.delete(Lattice_xml, np.where(Lattice_xml == \"\")).astype(int)\n",
    "    Lattice_Fin = np.reshape(Lattice_xml, dims[::-1])\n",
    "\n",
    "    # Fills in universes, determines positions for [ and ] and seperates into lines matching shape\n",
    "    py_file.write(f\"universes=\" + (len(dims) - 1) * \"[\")\n",
    "    if len(dims) == 2:\n",
    "        dims = np.append(dims, 1)[::-1]\n",
    "        Lattice_Fin = np.reshape(Lattice_Fin, dims)\n",
    "    else:\n",
    "        dims = dims[::-1]\n",
    "    for i in range(dims[0]):\n",
    "        for j in range(dims[1]):\n",
    "            py_file.write(\"\\n\\t[\")\n",
    "            for k in range(dims[2]):\n",
    "                py_file.write(\"u{}\".format(Lattice_Fin[i, j, k]))\n",
    "                if k != dims[2] - 1:\n",
    "                    py_file.write(\", \")\n",
    "            py_file.write(\"]\")\n",
    "            if j != dims[1] - 1:\n",
    "                py_file.write(\",\")\n",
    "        if i != dims[0] - 1:\n",
    "            py_file.write(\"],[\")\n",
    "    py_file.write((len(pitch) - 1) * \"]\" + \")\\n\")\n",
    "\n",
    "\n",
    "def Convert_Setting_Value(Sett_Val=None):\n",
    "    # Tests if Sett_Val is bool arg as string\n",
    "    if Sett_Val == \"true\":\n",
    "        Sett_Val = True\n",
    "    elif Sett_Val == \"false\":\n",
    "        Sett_Val = False\n",
    "    # Tests and corrects if Sett_Val is an int or float value\n",
    "    else:\n",
    "        try:\n",
    "            Sett_Val = float(Sett_Val)\n",
    "        except:\n",
    "            None  # Val is str\n",
    "        try:\n",
    "            Sett_Val = int(Sett_Val)\n",
    "        except:\n",
    "            None  # Val is str or float\n",
    "    # Otherwise returns str as it was initially input\n",
    "    return Sett_Val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# XML Parser/Translator Functions\n",
    "def Materials_XML_Parser(XML_file=\"materials.xml\", py_file=None):\n",
    "    \"\"\"Sub-parcer for materials\n",
    "\n",
    "    .. version:: 0.1.5\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if py_file == None:\n",
    "        py_file = open(\"Materials_Only.py\", \"t+w\")\n",
    "        py_file.write(\"import mcdc\\nimport numpy as np\\n\\n\")\n",
    "    else:\n",
    "        py_file.write(\n",
    "            \"\\n\" + 30 * \"#\" + \"\\n#__________Materials__________\\n\" + 30 * \"#\" + \"\\n\\n\"\n",
    "        )\n",
    "    Mats_Parse = et.parse(XML_file)\n",
    "    Mats_Root = Mats_Parse.getroot()\n",
    "    if Mats_Root.tag == \"model\":\n",
    "        Mats_Root = Mats_Root.find(\"materials\")\n",
    "\n",
    "    if Mats_Root.find(\"cross_sections\") != None:\n",
    "        MXS_File = h5py.File(Mats_Root.find(\"cross_sections\").text, \"r\")\n",
    "\n",
    "        # Create MC/DC MGXS\n",
    "        file_name = \"mcdc-\" + Mats_Root.find(\"cross_sections\").text\n",
    "        with h5py.File(file_name, \"w\") as f:\n",
    "            for material in list(MXS_File.keys()):\n",
    "                for temperature in list(MXS_File[material].keys()):\n",
    "                    if temperature == \"kTs\":\n",
    "                        continue\n",
    "\n",
    "                    name = material + \"-\" + temperature + \"/\"\n",
    "                    data = MXS_File[material][temperature]\n",
    "\n",
    "                    total = data[\"total\"][:]\n",
    "                    G = len(total)\n",
    "\n",
    "                    fission = np.zeros(G)\n",
    "                    nu = np.zeros(G)\n",
    "                    chi = np.zeros((G, G))\n",
    "\n",
    "                    if \"fission\" in list(data.keys()):\n",
    "                        fission = data[\"fission\"][:]\n",
    "                        nu_fission = data[\"nu-fission\"][:]\n",
    "                        nu = nu_fission / fission\n",
    "\n",
    "                        chi_1d = data[\"chi\"][:]\n",
    "                        for g in range(G):\n",
    "                            chi[g, :] = chi_1d[g]\n",
    "\n",
    "                    absorption = data[\"absorption\"][:]\n",
    "                    capture = absorption - fission\n",
    "                    scatter = Reconstruct_Scatter_Matrix(data)\n",
    "\n",
    "                    f.create_dataset(name + \"capture\", data=capture)\n",
    "                    f.create_dataset(name + \"fission\", data=fission)\n",
    "                    f.create_dataset(name + \"scatter\", data=scatter)\n",
    "                    f.create_dataset(name + \"nu\", data=nu)\n",
    "                    f.create_dataset(name + \"chi\", data=chi)\n",
    "\n",
    "        py_file.write(\n",
    "            f\"import h5py\\nMXS_Lib = h5py.File('mcdc-{Mats_Root.find('cross_sections').text}')\\n\"\n",
    "        )\n",
    "\n",
    "    for Mat in Mats_Root.findall(\"material\"):\n",
    "        Mat_ID = int(Mat.get(\"id\"))\n",
    "        Mat_name = Mat.get(\"name\")\n",
    "        if Mat_name != None:\n",
    "            py_file.write(f\"# Material Name: {Mat_name}\\n\")\n",
    "        if Mat.get(\"temperature\") != None:\n",
    "            py_file.write(f\"# Temperature: {Mat.get('temperature')}K\\n\")\n",
    "        if Mat.find(\"sab\") != None:\n",
    "            for Sab in Mat.findall(\"sab\"):\n",
    "                Sab_name = Sab.get(\"name\")\n",
    "                py_file.write(f\"# S(a,b): {Sab_name} (Not Implemented)\\n\")\n",
    "        if Mat.get(\"depletable\") != None:\n",
    "            py_file.write(\"# Depletable\\n\")\n",
    "\n",
    "        density_units = Mat.find(\"density\").get(\"units\")\n",
    "        sum_density = False\n",
    "        MACRO_Pull = False\n",
    "        if density_units != \"sum\" and density_units != \"macro\":\n",
    "            density = float(Mat.find(\"density\").get(\"value\"))\n",
    "            if density_units == \"g/cm3\" or density_units == \"g/cc\":\n",
    "                density *= 1\n",
    "                den_in_atom = False\n",
    "            elif density_units == \"kg/m3\":\n",
    "                density *= 0.001\n",
    "                den_in_atom = False\n",
    "            elif density_units == \"atom/barn-cm\":\n",
    "                density *= 1\n",
    "                den_in_atom = True\n",
    "            elif density_units == \"atom/cm3\" or density_units == \"atom/cc\":\n",
    "                density *= 1.0e-24\n",
    "                den_in_atom = True\n",
    "        elif density_units == \"sum\":\n",
    "            sum_density = True\n",
    "            den_in_atom = True\n",
    "            density = 0\n",
    "        elif density_units == \"macro\":\n",
    "            MACRO_Pull = True\n",
    "\n",
    "        if not MACRO_Pull:\n",
    "            Nuc_Names = np.array([])\n",
    "            Nuc_Den_Values = np.array([])\n",
    "            Nuc_Den_Types = np.array([])\n",
    "            for Nuc in Mat.findall(\"nuclide\"):\n",
    "                Nuc_Names = np.append(Nuc_Names, Nuc.get(\"name\"))\n",
    "                if Nuc.get(\"ao\") != None:\n",
    "                    Nuc_Den_Values = np.append(Nuc_Den_Values, float(Nuc.get(\"ao\")))\n",
    "                    Nuc_Den_Types = np.append(Nuc_Den_Types, \"ao\")\n",
    "                elif Nuc.get(\"wo\") != None:\n",
    "                    Nuc_Den_Values = np.append(Nuc_Den_Values, float(Nuc.get(\"wo\")))\n",
    "                    Nuc_Den_Types = np.append(Nuc_Den_Types, \"wo\")\n",
    "                else:\n",
    "                    print(\"No type\")\n",
    "            AVG_Molar_Mass = Average_Molar_Mass(\n",
    "                Nuc_Names, Nuc_Den_Values, Nuc_Den_Types\n",
    "            )\n",
    "            percent_in_atom = np.all(Nuc_Den_Types == \"ao\")\n",
    "\n",
    "            if sum_density:\n",
    "                density = np.sum(Nuc_Den_Values)\n",
    "            if not percent_in_atom:\n",
    "                for n, nuc in enumerate(Nuc_Names):\n",
    "                    Nuc_Den_Values[n] *= AVG_Molar_Mass / Atomic_Mass(nuc)\n",
    "            sum_percent = np.sum(Nuc_Den_Values)\n",
    "            Nuc_Den_Values /= sum_percent\n",
    "            if not den_in_atom:\n",
    "                density *= AVAGADRO / AVG_Molar_Mass * 1e-24\n",
    "            Nuc_Den_Values *= density\n",
    "\n",
    "            py_file.write(f\"m{Mat_ID} = mcdc.material(\")\n",
    "            py_file.write(\"nuclides=[\\n\")\n",
    "            for i in range(len(Nuc_Names)):\n",
    "                if Nuc_Names[i] == \"U234\" or Nuc_Names[i] == \"Th232\" or Nuc_Names[i] == \"Pu241\" or Nuc_Names[i] == \"U236\":\n",
    "                    continue\n",
    "                if Nuc_Names[i] == \"C0\":\n",
    "                    Nuc_Names[i] == \"C12\"\n",
    "                py_file.write(f\"\\t['{Nuc_Names[i]}',{Nuc_Den_Values[i]}]\")\n",
    "                if Nuc_Names[i] != Nuc_Names[-1]:\n",
    "                    py_file.write(\",\\n\")\n",
    "                else:\n",
    "                    py_file.write(\"])\\n\")\n",
    "\n",
    "        elif MACRO_Pull:\n",
    "            py_file.write(f\"# Cross-sections From: mcdc-{MXS_File.filename}\\n\")\n",
    "            Mat_Key = Mat.find(\"macroscopic\").get(\"name\")\n",
    "            OpenMC_SubKey = list(MXS_File[Mat_Key].keys())[0]\n",
    "            py_file.write(f\"M{Mat_ID}_Lib = MXS_Lib['{Mat_Key}-{OpenMC_SubKey}']\\n\")\n",
    "            py_file.write(f\"m{Mat_ID} = mcdc.material(\\n\")\n",
    "            py_file.write(f\"capture = M{Mat_ID}_Lib['capture'],\\n\")\n",
    "            py_file.write(f\"scatter = M{Mat_ID}_Lib['scatter'],\\n\")\n",
    "            py_file.write(f\"fission = M{Mat_ID}_Lib['fission'],\\n\")\n",
    "            py_file.write(f\"nu_p = M{Mat_ID}_Lib['nu'],\\n\")\n",
    "            py_file.write(f\"chi_p = M{Mat_ID}_Lib['chi'],\\n\")\n",
    "            py_file.write(f\")\\n\")\n",
    "\n",
    "    py_file.write(f\"mvoid = mcdc.material(nuclides=[['N14',1e-10]])\")\n",
    "    if Mats_Root.find(\"cross_sections\") != None:\n",
    "        MXS_File.close()\n",
    "        py_file.write(\"MXS_Lib.close()\\n\")\n",
    "\n",
    "    if py_file.name == \"Materials_Only.py\":\n",
    "        py_file.close()\n",
    "        print(f\"Materials MCDC File: ./{py_file.name}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_universes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Geometry_XML_Parser(XML_file=\"geometry.xml\", py_file=None):\n",
    "    \"\"\"Subparcer for geometry\n",
    "\n",
    "    .. version:: 0.1.4\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if py_file == None:\n",
    "        py_file = open(\"Geometry_Only.py\", \"t+w\")\n",
    "        py_file.write(\"import mcdc\\n\\n\")\n",
    "    else:\n",
    "        py_file.write(\n",
    "            \"\\n\" + 30 * \"#\" + \"\\n#__________Geometry__________\\n\" + 30 * \"#\" + \"\\n\\n\"\n",
    "        )\n",
    "    Geom_Parse = et.parse(XML_file)\n",
    "    Geom_Root = Geom_Parse.getroot()\n",
    "    if Geom_Root.tag == \"model\":\n",
    "        Geom_Root = Geom_Root.find(\"geometry\")\n",
    "\n",
    "    py_file.write(\"# Surface(s)\\n\")\n",
    "    for Surf in Geom_Root.findall(\"surface\"):\n",
    "        Surf_ID = int(Surf.get(\"id\"))\n",
    "        Surf_type = Surf.get(\"type\")\n",
    "        Surf_Coeffs = [float(val) for val in Surf.get(\"coeffs\").split()]\n",
    "        py_file.write(\"s{} = mcdc.surface(\".format(Surf_ID))\n",
    "\n",
    "        # PLANE GEOMETRY\n",
    "        if Surf_type == \"x-plane\":\n",
    "            Surf_type = \"plane-x\"\n",
    "            py_file.write(\"'{}', x={f[0]}, \".format(Surf_type, f=Surf_Coeffs))\n",
    "        elif Surf_type == \"y-plane\":\n",
    "            Surf_type = \"plane-y\"\n",
    "            py_file.write(\"'{}', y={f[0]}, \".format(Surf_type, f=Surf_Coeffs))\n",
    "        elif Surf_type == \"z-plane\":\n",
    "            Surf_type = \"plane-z\"\n",
    "            py_file.write(\"'{}', z={f[0]}, \".format(Surf_type, f=Surf_Coeffs))\n",
    "        elif Surf_type == \"plane\":\n",
    "            py_file.write(\n",
    "                \"'{}', A={f[0]}, B={f[1]}, C={f[2]}, D={f[3]}, \".format(\n",
    "                    Surf_type, f=Surf_Coeffs\n",
    "                )\n",
    "            )\n",
    "        # CYLINDER GEOMETRY\n",
    "        elif Surf_type == \"x-cylinder\":\n",
    "            Surf_type = \"cylinder-x\"\n",
    "            py_file.write(\n",
    "                \"'{}', center=[{f[0]}, {f[1]}], radius={f[2]}, \".format(\n",
    "                    Surf_type, f=Surf_Coeffs\n",
    "                )\n",
    "            )\n",
    "        elif Surf_type == \"y-cylinder\":\n",
    "            Surf_type = \"cylinder-y\"\n",
    "            py_file.write(\n",
    "                \"'{}', center=[{f[0]}, {f[1]}], radius={f[2]}, \".format(\n",
    "                    Surf_type, f=Surf_Coeffs\n",
    "                )\n",
    "            )\n",
    "        elif Surf_type == \"z-cylinder\":\n",
    "            Surf_type = \"cylinder-z\"\n",
    "            py_file.write(\n",
    "                \"'{}', center=[{f[0]}, {f[1]}], radius={f[2]}, \".format(\n",
    "                    Surf_type, f=Surf_Coeffs\n",
    "                )\n",
    "            )\n",
    "        # SPHERE GEOMETRY\n",
    "        elif Surf_type == \"sphere\":\n",
    "            py_file.write(\n",
    "                \"'{}', center=[{f[0]}, {f[1]}, {f[2]}], radius={f[3]}, \".format(\n",
    "                    Surf_type, f=Surf_Coeffs\n",
    "                )\n",
    "            )\n",
    "        # QUADRIC DEFINED GEOMETRY\n",
    "        elif Surf_type == \"quadric\":\n",
    "            py_file.write(\n",
    "                \"'{}', A={f[0]}, B={f[1]}, C={f[2]}, D={f[3]}, E={f[4]}, F={f[5]}, G={f[6]}, H={f[7]}, I={f[8]}, J={f[9]}, \".format(\n",
    "                    Surf_type, f=Surf_Coeffs\n",
    "                )\n",
    "            )\n",
    "        elif Surf_type == \"x-cone\":\n",
    "            Surf_type = \"quadric\"\n",
    "            R2 = -Surf_Coeffs[3]\n",
    "            G = -2 * R2 * Surf_Coeffs[0]\n",
    "            H = -2 * Surf_Coeffs[1]\n",
    "            I = -2 * Surf_Coeffs[2]\n",
    "            J = R2 * Surf_Coeffs[0] ** 2 + Surf_Coeffs[1] ** 2 + Surf_Coeffs[2] ** 2\n",
    "            py_file.write(\n",
    "                f\"'{Surf_type}', A={R2}, B=1, C=1, G={G}, H={H}, I={I}, J={J}, \"\n",
    "            )\n",
    "        elif Surf_type == \"y-cone\":\n",
    "            Surf_type = \"quadric\"\n",
    "            R2 = -Surf_Coeffs[3]\n",
    "            G = -2 * Surf_Coeffs[0]\n",
    "            H = -2 * R2 * Surf_Coeffs[1]\n",
    "            I = -2 * Surf_Coeffs[2]\n",
    "            J = Surf_Coeffs[0] ** 2 + R2 * Surf_Coeffs[1] ** 2 + Surf_Coeffs[2] ** 2\n",
    "            py_file.write(\n",
    "                f\"'{Surf_type}', A=1, B={R2}, C=1, G={G}, H={H}, I={I}, J={J}, \"\n",
    "            )\n",
    "        elif Surf_type == \"z-cone\":\n",
    "            Surf_type = \"quadric\"\n",
    "            R2 = -Surf_Coeffs[3]\n",
    "            H = -2 * Surf_Coeffs[0]\n",
    "            I = -2 * Surf_Coeffs[1]\n",
    "            G = -2 * R2 * Surf_Coeffs[2]\n",
    "            J = Surf_Coeffs[0] ** 2 + Surf_Coeffs[1] ** 2 + R2 * Surf_Coeffs[2] ** 2\n",
    "            py_file.write(\n",
    "                f\"'{Surf_type}', A=1, B=1, C={R2}, G={G}, H={H}, I={I}, J={J}, \"\n",
    "            )\n",
    "        # Note: General Cone in OpenMC is saved as a quadric\n",
    "        # NOT TRANSLATABLE GEOMETRY (Torus)\n",
    "        else:\n",
    "            py_file.write(f\")# {Surf_type} not supported\")\n",
    "\n",
    "        Surf_Bound = Surf.get(\"boundary\")\n",
    "        if Surf_Bound == None or Surf_Bound == \"transmission\":\n",
    "            bc = \"interface\"\n",
    "        elif Surf_Bound == \"reflective\" or Surf_Bound == \"white\":\n",
    "            bc = \"reflective\"\n",
    "        elif Surf_Bound == \"vacuum\":\n",
    "            bc = \"vacuum\"\n",
    "        else:\n",
    "            print(\"Boundary condition not accepted, defaulted to interface\")\n",
    "            bc = \"interface\"\n",
    "        py_file.write(f\"bc='{bc}')\")\n",
    "\n",
    "        if Surf.get(\"name\") != None:\n",
    "            py_file.write(f\" # Name: {Surf.get('name')}\\n\")\n",
    "        else:\n",
    "            py_file.write(\"\\n\")\n",
    "\n",
    "    Written_Cells = []\n",
    "    py_file.write(\"\\n# Material Cell(s)\\n\")\n",
    "    for Cell in Geom_Root.findall(\"cell\"):\n",
    "        if Cell.get(\"material\") == None:\n",
    "            continue\n",
    "        Cell_ID = int(Cell.get(\"id\"))\n",
    "        Written_Cells.append(Cell_ID)\n",
    "\n",
    "        py_file.write(\"c{} = mcdc.cell(\".format(Cell_ID))\n",
    "        Region_Fill(py_file=py_file, Cell=Cell)\n",
    "        py_file.write(f\"fill=\")\n",
    "\n",
    "        Mat_IDs = np.array([val for val in Cell.get(\"material\").split()])\n",
    "        for i in range(len(Mat_IDs)):\n",
    "            py_file.write(f\"m{Mat_IDs[i]}\")\n",
    "            if Mat_IDs[i] != Mat_IDs[-1]:\n",
    "                py_file.write(\", \")\n",
    "        py_file.write(\")\")\n",
    "\n",
    "        if Cell.get(\"name\") != None:\n",
    "            py_file.write(f\" # Name: {Cell.get('name')}\\n\")\n",
    "        else:\n",
    "            py_file.write(f\"\\n\")\n",
    "\n",
    "    py_file.write(\"# Root Universe Cells List:\\nu0_cells = []\\n\")\n",
    "    py_file.write(\"# Material Universe(s)\\n\")\n",
    "    # FIX: this line needs to be present for universes\n",
    "    # Written_Universes = Write_Universes(Geom_Root, py_file)\n",
    "\n",
    "    Lat_IDs_List = []\n",
    "    for Lattice in Geom_Root.findall(\"lattice\"):\n",
    "        Lat_IDs_List.append(int(Lattice.get(\"id\")))\n",
    "\n",
    "    Exclude_List = Lat_IDs_List.copy()\n",
    "    Writing_Complex = True\n",
    "    Level = 1\n",
    "\n",
    "    while Writing_Complex:\n",
    "        if len(Geom_Root.findall(\"cell\")) == (len(Written_Cells) + len(Lat_IDs_List)):\n",
    "            Writing_Complex = False\n",
    "            continue\n",
    "        py_file.write(f\"\\n# Complex Cell(s) Level {Level}\\n\")\n",
    "        for Cell in Geom_Root.findall(\"cell\"):\n",
    "            if Cell.get(\"fill\") == None:\n",
    "                continue\n",
    "            Fill_ID = int(Cell.get(\"fill\"))\n",
    "            if not (Fill_ID in Exclude_List) and (Fill_ID in Written_Universes):\n",
    "                Cell_ID = int(Cell.get(\"id\"))\n",
    "                Written_Cells.append(Cell_ID)\n",
    "\n",
    "                py_file.write(\"c{} = mcdc.cell(\".format(Cell_ID))\n",
    "\n",
    "                Region_Fill(py_file=py_file, Cell=Cell)\n",
    "                py_file.write(f\"fill=u{Fill_ID}\")\n",
    "\n",
    "                if Cell.get(\"translation\") is not None:\n",
    "                    tr = Cell.get(\"translation\").split()\n",
    "                    py_file.write(f\", translation=[{tr[0]}, {tr[1]}, {tr[2]}]\")\n",
    "\n",
    "                if Cell.get(\"rotation\") is not None:\n",
    "                    rot = Cell.get(\"rotation\").split()[0]\n",
    "                    py_file.write(f\", rotation=[{rot[0]}, {rot[1]}, {rot[2]}]\")\n",
    "\n",
    "                py_file.write(\")\")\n",
    "\n",
    "                if Cell.get(\"name\") != None:\n",
    "                    py_file.write(f\" # Name: {Cell.get('name')}\\n\")\n",
    "                else:\n",
    "                    py_file.write(f\"\\n\")\n",
    "        py_file.write(f\"# Complex Universe(s) Level {Level}\\n\")\n",
    "        Complex_Universes = Write_Universes(\n",
    "            Geom_Root,\n",
    "            py_file,\n",
    "            Complex=True,\n",
    "            Exclude_List=Exclude_List,\n",
    "            Defined_Cells=Written_Cells,\n",
    "        )\n",
    "        Exclude_List = Lat_IDs_List + Written_Universes\n",
    "        Written_Universes += Complex_Universes\n",
    "        if len(Complex_Universes) == 0:\n",
    "            Writing_Complex = False\n",
    "        else:\n",
    "            Level += 1\n",
    "\n",
    "    for Lattice in Geom_Root.findall(\n",
    "        \"lattice\"\n",
    "    ):  # Update so that if universe is redefefined, it is instead updated\n",
    "        Lat_ID = Lattice.get(\"id\")\n",
    "        Write_Rect_Lattice(Lattice, py_file, Lat_ID)\n",
    "        for Cell in Geom_Root.findall(\"cell\"):\n",
    "            if Cell.get(\"fill\") == Lat_ID:\n",
    "                Cell_ID = int(Cell.get(\"id\"))\n",
    "\n",
    "                py_file.write(\"c{} = mcdc.cell(\".format(Cell_ID))\n",
    "                Region_Fill(py_file=py_file, Cell=Cell)\n",
    "                py_file.write(f\"fill=Lattice{Lat_ID}\")\n",
    "\n",
    "                if Cell.get(\"translation\") is not None:\n",
    "                    tr = Cell.get(\"translation\").split()\n",
    "                    py_file.write(f\", translation=[{tr[0]}, {tr[1]}, {tr[2]}]\")\n",
    "\n",
    "                if Cell.get(\"rotation\") is not None:\n",
    "                    rot = Cell.get(\"rotation\").split()[0]\n",
    "                    py_file.write(f\", rotation=[{rot[0]}, {rot[1]}, {rot[2]}]\")\n",
    "\n",
    "                py_file.write(\")\")\n",
    "\n",
    "                if Cell.get(\"name\") != None:\n",
    "                    py_file.write(f\" # Name: {Cell.get('name')}\\n\")\n",
    "                else:\n",
    "                    py_file.write(f\"\\n\")\n",
    "        Lattice_Universe = Write_Universes(Geom_Root, py_file, Lat_ID)\n",
    "        Written_Universes += Lattice_Universe\n",
    "\n",
    "    if py_file.name == \"Geometry_Only.py\":\n",
    "        py_file.close()\n",
    "        print(f\"Geometry MCDC File: ./{py_file.name}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Settings_XML_Parser(XML_file=\"settings.xml\", py_file=None):\n",
    "    if py_file == None:\n",
    "        py_file = open(\"Settings_Only.py\", \"t+w\")\n",
    "        py_file.write(\"import mcdc\\nimport numpy as np\\n\\n\")\n",
    "    else:\n",
    "        py_file.write(\n",
    "            \"\\n\" + 30 * \"#\" + \"\\n#__________Settings__________\\n\" + 30 * \"#\" + \"\\n\\n\"\n",
    "        )\n",
    "\n",
    "    Sett_Parse = et.parse(XML_file)\n",
    "\n",
    "    Sett_Root = Sett_Parse.getroot()\n",
    "    if Sett_Root.tag == \"model\":\n",
    "        Sett_Root = Sett_Root.find(\"settings\")\n",
    "\n",
    "    Settings_Dict = {}\n",
    "\n",
    "    for Sett_key in [_.tag for _ in Sett_Root]:\n",
    "        if isinstance(Sett_key,str) == 0:\n",
    "            continue\n",
    "        if Sett_key in [\"particles\", \"batches\", \"inactive\", \"source\", \"output\"]:\n",
    "            continue  # Ignores listed common settings\n",
    "        elif Sett_key in [\n",
    "            \"cutoff\",\n",
    "            \"keff_trigger\",\n",
    "            \"mesh\",\n",
    "            \"resonance_scattering\",\n",
    "            \"state_point\",\n",
    "            \"source_point\",\n",
    "            \"surf_source_read\",\n",
    "            \"surf_source_write\",\n",
    "            \"tabular_legendre\",\n",
    "            \"trigger\",\n",
    "            \"volume_calc\",\n",
    "            \"weight_windows\",\n",
    "            \"weight_window_generator\",\n",
    "            \"weight_window_checkpoints\",\n",
    "        ]:  # Settings with Sub-Dictionaries\n",
    "            Sett_Val = {}\n",
    "            Parent = Sett_Root.find(Sett_key)\n",
    "            if Parent is not None:\n",
    "                for Sub in Parent:\n",
    "                    Sub_key = Sub.tag\n",
    "                    Sub_Val = Sub.text\n",
    "                    Sett_Val[Sub_key] = Convert_Setting_Value(Sub_Val)\n",
    "        else:  # All other uncommon settings with simple values\n",
    "            Element = Sett_Root.find(Sett_key)\n",
    "            if Element is not None and Element.text is not None:\n",
    "                Sett_Val = Element.text\n",
    "                Sett_Val = Convert_Setting_Value(Sett_Val)\n",
    "            else:\n",
    "                Sett_Val = None  # Or another default value if needed  \n",
    "        Settings_Dict[Sett_key] = Sett_Val\n",
    "\n",
    "    if len(Settings_Dict) != 1:\n",
    "        py_file.write(\"# Original Conditions (Some Not Implemented)\\n\")\n",
    "    for (\n",
    "        key\n",
    "    ) in (\n",
    "        Settings_Dict.keys()\n",
    "    ):  # Writes uncommon settings that are not implemented (Note: Weighting and Mesh not yet implemented)\n",
    "        if not key in [\"run_mode\", \"seed\"]:\n",
    "            py_file.write(f\"#\\t{key} = {Settings_Dict[key]}\\n\")\n",
    "\n",
    "    py_file.write(\"# Simulation Parameters\\n\")\n",
    "    # Possible modes: eigenvalue, fixed source, plot, volume, particle reset (Last three not implemented)\n",
    "    if Settings_Dict[\"run_mode\"] == \"eigenvalue\":\n",
    "        N_Particles = int(Sett_Root.find(\"particles\").text)\n",
    "        N_Batches = int(Sett_Root.find(\"batches\").text)\n",
    "        N_Inactive = int(Sett_Root.find(\"inactive\").text)\n",
    "        N_Active = N_Batches - N_Inactive\n",
    "        # FIX: I manually set these to a particle count I wanted for the icsbep benchmarks. Change to actually copy openmc\n",
    "        #py_file.write(f\"mcdc.eigenmode(N_inactive={N_Inactive}, N_active={N_Active})\\n\")\n",
    "        py_file.write(f\"mcdc.eigenmode(N_inactive=20, N_active=180)\\n\")\n",
    "        #py_file.write(f\"mcdc.setting(N_particle={N_Particles}\")\n",
    "        py_file.write(f\"mcdc.setting(N_particle=10000\")\n",
    "    elif Settings_Dict[\"run_mode\"] == \"fixed source\":\n",
    "        N_Particles = int(Sett_Root.find(\"particles\").text)\n",
    "        N_Batches = int(Sett_Root.find(\"batches\").text)\n",
    "        py_file.write(f\"mcdc.setting(N_particle={N_Particles}, N_batch={N_Batches}\")\n",
    "    else:\n",
    "        py_file.write(f\"# Run mode: {Settings_Dict['run_mode']} Not Supported\")\n",
    "\n",
    "    # Uses same seed int if recorded and closes settings function\n",
    "    if \"seed\" in Settings_Dict.keys():\n",
    "        py_file.write(f\", rng_seed={Settings_Dict['seed']})\\n\")\n",
    "    else:\n",
    "        py_file.write(\")\\n\")\n",
    "\n",
    "    py_file.write(\"\\n# Source Parameters\\n\")\n",
    "    Source = Sett_Root.find(\"source\")\n",
    "    if Source == None:\n",
    "        py_file.write(\n",
    "            \"# Particle: neutron\\n# Space Type: Point\\n mcdc.source(point=[0.0,0.0,0.0], prob=1.0)\\n\"\n",
    "        )\n",
    "    else:\n",
    "        Particle = Source.get(\"particle\")\n",
    "        if Particle == None:\n",
    "            Particle = \"neutron\"\n",
    "        # P_Type = Source.get('type')\n",
    "        openmc_source_strength = Source.get(\"strength\")\n",
    "        if openmc_source_strength == None:\n",
    "            Strength = 1.0\n",
    "        else:\n",
    "            Strength = float(Source.get(\"strength\"))\n",
    "        Space = Source.find(\"space\")\n",
    "        #Space_Type = Space.get(\"type\")\n",
    "        if Space.find(\"type\") is not None:\n",
    "            Space_Type = Space.find(\"type\").text \n",
    "        else:\n",
    "            Space_Type = \"point\"\n",
    "        \n",
    "\n",
    "\n",
    "        py_file.write(f\"# Particle: {Particle}\\n\")\n",
    "        py_file.write(f\"# Space Type: {Space_Type}\")\n",
    "\n",
    "        if Space_Type == \"point\":\n",
    "            if Space.find(\"type\") is not None:\n",
    "                Parameters = [\n",
    "                    float(val) for val in Space.find(\"parameters\").text.split()\n",
    "                ]\n",
    "            else:\n",
    "                Parameters = [0.0, 0.0, 0.0]\n",
    "            py_file.write(\n",
    "                \"\\nmcdc.source(point=[{P[0]},{P[1]},{P[2]}], prob={S})\\n\".format(\n",
    "                    P=Parameters, S=Strength\n",
    "                )\n",
    "            )\n",
    "        elif Space_Type == \"cartesian\":\n",
    "            Parameters = [0, 0, 0]\n",
    "            py_file.write(\" (Not Implemented, Replaced with Point)\\n\")\n",
    "            py_file.write(\n",
    "                \"mcdc.source(point=[{P[0]},{P[1]},{P[2]}], prob={S})\\n\".format(\n",
    "                    P=Parameters, S=Strength\n",
    "                )\n",
    "            )\n",
    "        elif Space_Type == \"box\" or Space_Type == \"fission\":\n",
    "            Parameters = [\n",
    "                #float(val) for val in Space.find(\"parameters\").text.split(\" \")\n",
    "                float(val) for val in Space.find(\"parameters\").text.split() if val.strip()\n",
    "            ]\n",
    "            py_file.write(\n",
    "                \"\\nmcdc.source(x=[{P[0]},{P[3]}], y=[{P[1]},{P[4]}], z=[{P[2]},{P[5]}], prob={S})\\n\".format(\n",
    "                    P=Parameters, S=Strength\n",
    "                )\n",
    "            )\n",
    "        elif Space_Type == \"spherical\":\n",
    "            Parameters = [float(val) for val in Space.get(\"origin\").split()]\n",
    "            Parameters += [\n",
    "                float(val) for val in Space.find(\"r\").get(\"parameters\").split()\n",
    "            ]\n",
    "            Parameters += [\n",
    "                float(val)\n",
    "                for val in Space.find(\"cos_theta\").get(\"parameters\").split()\n",
    "            ]\n",
    "            Parameters += [\n",
    "                float(val) for val in Space.find(\"phi\").get(\"parameters\").split()\n",
    "            ]\n",
    "            py_file.write(\" (Not Implemented, Replaced with Point)\\n\")\n",
    "            py_file.write(\n",
    "                \"mcdc.source(point=[{P[0]},{P[1]},{P[2]}], prob={S})\\n\".format(\n",
    "                    P=Parameters, S=Strength\n",
    "                )\n",
    "            )\n",
    "        elif Space_Type == \"cylindrical\":\n",
    "            Parameters = [0, 0, 0]\n",
    "            py_file.write(\" (Not Implemented, Replaced with Point)\\n\")\n",
    "            py_file.write(\n",
    "                \"mcdc.source(point=[{P[0]},{P[1]},{P[2]}], prob={S})\\n\".format(\n",
    "                    P=Parameters, S=Strength\n",
    "                )\n",
    "            )\n",
    "        elif Space_Type == \"mesh\":\n",
    "            Parameters = [0, 0, 0]\n",
    "            py_file.write(\" (Not Implemented, Replaced with Point)\\n\")\n",
    "            py_file.write(\n",
    "                \"nmcdc.source(point=[{P[0]},{P[1]},{P[2]}], prob={S})\\n\".format(\n",
    "                    P=Parameters, S=Strength\n",
    "                )\n",
    "            )\n",
    "\n",
    "    if py_file.name == \"Settings_Only.py\":\n",
    "        py_file.close()\n",
    "        print(f\"Settings MCDC File: ./{py_file.name}\")\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ultimate function for running all parsers\n",
    "def OpenMC_to_MCDC(\n",
    "    output_name=\"input.py\",\n",
    "    materials_xml=\"materials.xml\",\n",
    "    geometry_xml=\"geometry.xml\",\n",
    "    settings_xml=\"settings.xml\",\n",
    "    model_xml=None,\n",
    "):\n",
    "    \"\"\"Constructs python file (output_name) into folder location. Defines nuclear system input deck compatable with MC/DC\n",
    "    terminology from OpenMC input deck files (materials.xml, geometry.xml, settings.xml, etc.) within folder location.\n",
    "\n",
    "    .. version:: 0.1.4\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    output_name : str, optional\n",
    "        Name of new python file, must end in '.py'\n",
    "    materials_xml : str, optional\n",
    "        Name of materials file, must end in '.xml'\n",
    "    geometry_xml : str, optional\n",
    "        Name of geometry file, must end in '.xml'\n",
    "    settings_xml : str, optional\n",
    "        Name of settings file, must end in '.xml'\n",
    "    model_xml : str, optional\n",
    "        Name of model file, must end in '.xml',\n",
    "        overrides individual xml files\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\\n\n",
    "    Prints created file link\n",
    "    \"\"\"\n",
    "\n",
    "    # Check input parameters\n",
    "    assert output_name[-3:] == \".py\", \"New file must be a python file\"\n",
    "    assert materials_xml[-4:] == \".xml\", \"Improper Geometry input file name\"\n",
    "    assert geometry_xml[-4:] == \".xml\", \"Improper Materials input file name\"\n",
    "    assert settings_xml[-4:] == \".xml\", \"Improper Settings input file name\"\n",
    "    if model_xml is not None and os.path.isfile(model_xml):\n",
    "        assert model_xml[-4:] == \".xml\", \"Improper Model input file name\"\n",
    "        materials_xml = model_xml\n",
    "        geometry_xml = model_xml\n",
    "        settings_xml = model_xml\n",
    "\n",
    "    # Create file\n",
    "    MCDC_Code = open(output_name, \"t+w\")\n",
    "\n",
    "    # Imports\n",
    "    MCDC_Code.write(\"import mcdc\\nimport numpy as np\\n\\n\")\n",
    "\n",
    "    # Parse materials, geometry, and settings\n",
    "    Materials_XML_Parser(XML_file=materials_xml, py_file=MCDC_Code)\n",
    "    Geometry_XML_Parser(XML_file=geometry_xml, py_file=MCDC_Code)\n",
    "    Settings_XML_Parser(XML_file=settings_xml, py_file=MCDC_Code)\n",
    "\n",
    "    MCDC_Code.write(\"\\nmcdc.run()\\n\\n\")\n",
    "\n",
    "    # Close file and report\n",
    "    MCDC_Code.close()\n",
    "    print(\"MCDC Input File Constructed: .\\{}\".format(output_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_and_translate(base_dir):\n",
    "    \"\"\"\n",
    "    Recursively find all openmc directories containing the required XML files, \n",
    "    create mcdc directory next to them, and run the translator.\n",
    "    \"\"\"\n",
    "    required_files = {\"materials.xml\", \"geometry.xml\", \"settings.xml\"}\n",
    "    num_failed = 0\n",
    "    num_built = 0\n",
    "    failed_list = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        #if root != \"/usr/workspace/northroj/dane_mcdc_openmc/icsbep/openmc/heu-met-fast-002/openmc/case-5\":\n",
    "        #    continue\n",
    "        try:\n",
    "            # Check for case 1: XMLs directly in openmc folder\n",
    "            if os.path.basename(root) == \"openmc\" and required_files.issubset(set(files)):\n",
    "                openmc_dir = root\n",
    "                parent_dir = os.path.dirname(openmc_dir)\n",
    "                problem_name = os.path.basename(parent_dir)\n",
    "                mcdc_dir = os.path.join(parent_dir, \"mcdc\")\n",
    "                \n",
    "                # Create mcdc directory if it doesn't exist\n",
    "                if not os.path.exists(mcdc_dir):\n",
    "                    os.makedirs(mcdc_dir)\n",
    "\n",
    "                # Name the output file using the problem name\n",
    "                output_name = os.path.join(mcdc_dir, f\"{problem_name}.py\")\n",
    "                materials_xml = os.path.join(openmc_dir, \"materials.xml\")\n",
    "                geometry_xml = os.path.join(openmc_dir, \"geometry.xml\")\n",
    "                settings_xml = os.path.join(openmc_dir, \"settings.xml\")\n",
    "                \n",
    "                # Run the translator\n",
    "                print(f\"Translating OpenMC inputs in {openmc_dir} to {output_name}...\")\n",
    "                OpenMC_to_MCDC(\n",
    "                    output_name=output_name,\n",
    "                    materials_xml=materials_xml,\n",
    "                    geometry_xml=geometry_xml,\n",
    "                    settings_xml=settings_xml,\n",
    "                )\n",
    "                print(f\"Translation complete: {output_name}\")\n",
    "                num_built += 1\n",
    "\n",
    "            # Check for case 2: XMLs in subfolders of openmc (e.g., openmc/<casename>/)\n",
    "            elif os.path.basename(os.path.dirname(root)) == \"openmc\" and required_files.issubset(set(files)):\n",
    "                case_dir = root\n",
    "                openmc_dir = os.path.dirname(case_dir)\n",
    "                parent_dir = os.path.dirname(openmc_dir)\n",
    "                problem_name = os.path.basename(parent_dir)\n",
    "                case_name = os.path.basename(case_dir)\n",
    "                mcdc_dir = os.path.join(parent_dir, \"mcdc\")\n",
    "                \n",
    "                # Create mcdc directory if it doesn't exist\n",
    "                if not os.path.exists(mcdc_dir):\n",
    "                    os.makedirs(mcdc_dir)\n",
    "\n",
    "                # Name the output file using problem name and case name\n",
    "                output_name = os.path.join(mcdc_dir, f\"{problem_name}_{case_name}.py\")\n",
    "                materials_xml = os.path.join(case_dir, \"materials.xml\")\n",
    "                geometry_xml = os.path.join(case_dir, \"geometry.xml\")\n",
    "                settings_xml = os.path.join(case_dir, \"settings.xml\")\n",
    "                \n",
    "                # Run the translator\n",
    "                print(f\"Translating OpenMC inputs in {case_dir} to {output_name}...\")\n",
    "                OpenMC_to_MCDC(\n",
    "                    output_name=output_name,\n",
    "                    materials_xml=materials_xml,\n",
    "                    geometry_xml=geometry_xml,\n",
    "                    settings_xml=settings_xml,\n",
    "                )\n",
    "                print(f\"Translation complete: {output_name}\")\n",
    "                num_built += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Exeption: {e}\")\n",
    "            num_failed += 1\n",
    "            failed_list.append(openmc_dir)\n",
    "        \n",
    "    print(num_failed, \"failures\")\n",
    "    print(num_built, \"built\")\n",
    "    print(failed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'find_and_translate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Specify the base directory to start the search\u001b[39;00m\n\u001b[1;32m      2\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<path_to_MCDC-verification>/MCDC-verification/icsbep/openmc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mfind_and_translate\u001b[49m(base_dir)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'find_and_translate' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify the base directory to start the search\n",
    "base_dir = \"<path_to_MCDC-verification>/MCDC-verification/icsbep/openmc\"\n",
    "find_and_translate(base_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmc_dane_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
